{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mxjCr_fKeSP5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionEncoding(nn.Module):\n",
        "  def __init__(self, seq_length, d_model):\n",
        "    super(PositionEncoding, self).__init__()\n",
        "    # output = (seq_length, d_model)\n",
        "    positions = torch.arange(0, seq_length, dtype = torch.float).unsqueeze(0)\n",
        "    for dim in range(d_model):\n",
        "      std_dim = dim//2 * 2\n",
        "      dim_term = torch.tensor([(1/1e4)** (2*std_dim/d_model)] * seq_length)\n",
        "      dim_term = torch.sin(torch.mul(positions, dim_term)) if dim % 2 == 0 else torch.cos(torch.mul(positions, dim_term))\n",
        "      if dim == 0:\n",
        "        self.myOutput = dim_term\n",
        "      else:\n",
        "        self.myOutput = torch.cat((self.myOutput, dim_term), dim = 0)\n",
        "    self.myOutput = self.myOutput.transpose(-1, -2)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.myOutput"
      ],
      "metadata": {
        "id": "N2u3WkXtPA3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BERTEmbedding(nn.Module):\n",
        "  def __init__(self, vocab_size, seq_length, n_segments, d_model, dropout):\n",
        "    super(BERTEmbedding, self).__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "    self.embed_segment = nn.Embedding(n_segments, d_model)\n",
        "    self.pe = PositionEncoding(seq_length, d_model)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, seq_input, seg_input):\n",
        "    x = self.embed_segment(seg_input) + self.embedding(seq_input) + self.pe(seq_input)\n",
        "    return self.dropout(x)"
      ],
      "metadata": {
        "id": "p5ASGvwPeduY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BERTModel(nn.Module):\n",
        "  def __init__(self, vocab_size, seq_length, n_segments, d_model, dropout):\n",
        "    super(BERTModel, self).__init__()\n",
        "    self.embed = BERTEmbedding(vocab_size, seq_length, n_segments, d_model, dropout)\n",
        "    encoder_layer = nn.TransformerEncoderLayer(d_model = d_model,\n",
        "                                               nhead = 8,\n",
        "                                               dropout = dropout)\n",
        "    self.bert = nn.TransformerEncoder(encoder_layer,\n",
        "                                      num_layers = 6,\n",
        "                                      mask_check = True)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, seq_input, seg_input):\n",
        "    output = self.embed(seq_input, seg_input)\n",
        "    output = self.bert(output)\n",
        "    output = self.dropout(output)\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "Clu1rhgoO2rG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "  VOCAB_SIZE = 20000\n",
        "  SEQ_LENGTH = 100\n",
        "  D_MODEL = 512\n",
        "  DROPOUT = 0.2\n",
        "  N_SEGMENTS = 3\n",
        "  BATCH_SIZE = 32\n",
        "\n",
        "  bert = BERTModel(VOCAB_SIZE,\n",
        "                   SEQ_LENGTH,\n",
        "                   N_SEGMENTS,\n",
        "                   D_MODEL,\n",
        "                   DROPOUT)\n",
        "  seq_input = torch.randint(0, VOCAB_SIZE, (BATCH_SIZE, SEQ_LENGTH))\n",
        "  seg_input = torch.randint(0, N_SEGMENTS, (BATCH_SIZE, SEQ_LENGTH))\n",
        "  print(bert(seq_input, seg_input).size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvZlnSVooC63",
        "outputId": "0b48e656-7b4d-48ac-9a75-ea5a14b671f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 100, 512])\n"
          ]
        }
      ]
    }
  ]
}